# LSP Development Guide

## Source Threading Architecture (v0.8.7+)

All LSP providers now support source-aware analysis for enhanced documentation extraction:

### Provider Constructor Patterns
```rust
// Enhanced constructors with source text and module resolver (v0.8.8)
CompletionProvider::new_with_index_and_source(ast, source, workspace_index, module_resolver)
SignatureHelpProvider::new_with_source(ast, source)
SymbolExtractor::new_with_source(source)

// Legacy constructors (still supported)
CompletionProvider::new_with_index(ast, workspace_index)  // uses empty source, no module resolver
SignatureHelpProvider::new(ast)  // uses empty source
SymbolExtractor::new()  // no documentation extraction
```

### ModuleResolver Integration (NEW v0.8.8) - (*Diataxis: How-to Guide*)

The CompletionProvider now supports pluggable module resolution for enhanced Perl module completion. This allows LSP features to resolve module names to file paths for improved functionality.

#### **Creating a Module Resolver**
```rust
use crate::module_resolver;
use std::sync::{Arc, Mutex};

// Create resolver closure in LSP server
let resolver = {
    let docs = self.documents.clone();        // Reference to open documents
    let folders = self.workspace_folders.clone();  // Reference to workspace folders
    Arc::new(move |module_name: &str| {
        module_resolver::resolve_module_to_path(&docs, &folders, module_name)
    })
};
```

#### **Integration with CompletionProvider**
```rust
// Pass resolver to completion provider
let provider = CompletionProvider::new_with_index_and_source(
    ast,                          // Parsed AST
    &doc.text,                   // Source text for documentation
    workspace_index,             // Workspace symbol index
    Some(resolver)               // Optional module resolver
);

// The provider can now resolve module references during completion
let completions = provider.get_completions_with_path(&doc.text, offset, Some(uri));
```

#### **Module Resolution Process**
1. **Fast Path**: Check already-open documents for matching module paths
2. **Standard Directories**: Search `lib/`, `./`, `local/lib/perl5/` in workspace folders  
3. **Path Conversion**: Transform `Module::Name` ‚Üí `Module/Name.pm`
4. **Timeout Protection**: 50ms maximum to prevent LSP blocking
5. **URI Generation**: Return proper `file://` URIs for LSP compatibility

#### **Benefits for LSP Features**
- **Enhanced Completions**: Module-aware completion suggestions
- **Go-to-Definition**: Navigate to module files from `use` statements
- **Hover Information**: Display module documentation and file paths
- **Future Extensibility**: Easy integration for new LSP features requiring module resolution

#### **Performance Considerations**
- **Bounded Search**: Time-limited filesystem operations (50ms timeout)
- **Cooperative Yielding**: Doesn't block LSP server during long searches
- **Caching Strategy**: Fast path checks open documents first
- **Generic Design**: Works with any document representation for flexibility

## Enhanced Cross-File Definition Resolution (v0.8.8+) (*Diataxis: How-to Guide* - Advanced LSP Development)

The v0.8.8+ releases introduce comprehensive Package::subroutine pattern resolution with sophisticated fallback mechanisms for robust cross-file navigation.

### Implementation Patterns for Package::Subroutine Resolution

#### Pattern 1: Regex-Based Symbol Detection
```rust
// Enhanced regex pattern for fully-qualified symbols
use regex::Regex;

let re = Regex::new(r"([A-Za-z_][A-Za-z0-9_]*(?:::[A-Za-z_][A-Za-z0-9_]*)*)")
    .unwrap();

for cap in re.captures_iter(&text_around) {
    if let Some(m) = cap.get(1) {
        if cursor_in_text >= m.start() && cursor_in_text <= m.end() {
            let parts: Vec<&str> = m.as_str().split("::").collect();
            if parts.len() >= 2 {
                let name = parts.last().unwrap().to_string();
                let pkg = parts[..parts.len() - 1].join("::");
                
                // Create SymbolKey for workspace index lookup
                let key = crate::workspace_index::SymbolKey {
                    pkg: pkg.clone().into(),
                    name: name.clone().into(),
                    sigil: None,
                    kind: crate::workspace_index::SymKind::Sub,
                };
                
                // Try workspace index resolution first
                if let Some(ref workspace_index) = self.workspace_index {
                    if let Some(def_location) = workspace_index.find_def(&key) {
                        return to_lsp_location(&def_location);
                    }
                }
            }
        }
    }
}
```

#### Pattern 2: Document Scanning Fallback
```rust
// Fallback: scan open documents for symbol definitions
let docs_snapshot: Vec<(String, DocumentState)> = documents
    .iter()
    .map(|(k, v)| (k.clone(), v.clone()))
    .collect();

for (doc_uri, doc_state) in docs_snapshot {
    if let Some(ref ast) = doc_state.ast {
        let symbols = self.extract_document_symbols(
            ast,
            &doc_state.text,
            &doc_uri,
        );
        for sym in symbols {
            if sym.name == name && sym.container_name.as_deref() == Some(&pkg) {
                return Ok(Some(json!([sym.location])));
            }
        }
    }
}
```

#### Pattern 3: Enhanced Reference Search with Dual Patterns
```rust
// Enhanced fallback: search for both qualified and unqualified references
let symbol_name = &symbol_key.name;
let package_name = &symbol_key.pkg;

// Search patterns: both "symbol_name" and "package::symbol_name"  
let patterns = vec![
    format!(r"\b{}\b", regex::escape(symbol_name)),
    format!(r"\b{}::{}\b", regex::escape(package_name), regex::escape(symbol_name)),
];

let mut enhanced_locations = Vec::new();
for pattern in patterns {
    if let Ok(search_regex) = regex::Regex::new(&pattern) {
        for (doc_uri, doc_state) in &docs_snapshot {
            let lines: Vec<&str> = doc_state.text.lines().collect();
            for (line_num, line) in lines.iter().enumerate() {
                for mat in search_regex.find_iter(line) {
                    enhanced_locations.push(json!({
                        "uri": doc_uri,
                        "range": {
                            "start": {
                                "line": line_num,
                                "character": mat.start(),
                            },
                            "end": {
                                "line": line_num,
                                "character": mat.end(),
                            },
                        },
                    }));
                }
            }
        }
    }
}

// Combine workspace index results with text search results  
workspace_locations.extend(enhanced_locations);
```

### Development Testing for Cross-File Features

#### Test Cases for Package::Subroutine Resolution
```rust
#[test]
fn test_cross_file_package_subroutine_resolution() {
    let mut server = LspServer::new();
    
    // Create Package module
    let package_content = r#"
package Utils;

sub utility_function {
    my ($param) = @_;
    return process($param);
}

1;
"#;
    
    // Create client code using Package::subroutine
    let client_content = r#"
use Utils;

sub main {
    Utils::utility_function("test");  # Cursor here for go-to-definition
}
"#;
    
    server.documents.lock().unwrap().insert(
        "file:///Utils.pm".to_string(),
        DocumentState::new(package_content),
    );
    
    server.documents.lock().unwrap().insert(
        "file:///main.pl".to_string(), 
        DocumentState::new(client_content),
    );
    
    // Test go-to-definition for Utils::utility_function
    let result = server.handle_definition(json!({
        "textDocument": {"uri": "file:///main.pl"},
        "position": {"line": 3, "character": 10}  // On "Utils::utility_function"
    }));
    
    assert!(result.is_ok());
    let locations = result.unwrap().unwrap();
    assert!(!locations.as_array().unwrap().is_empty());
    
    // Should point to Utils.pm function definition
    let location = &locations.as_array().unwrap()[0];
    assert_eq!(location["uri"], "file:///Utils.pm");
}

#[test]
fn test_definition_fallback_without_workspace_index() {
    let mut server = LspServer::new();
    server.workspace_index = None; // Force fallback mode
    
    // Same test as above - should still work via document scanning
    // ... test implementation
}

#[test]
fn test_enhanced_reference_search_dual_patterns() {
    let mut server = LspServer::new();
    
    let content = r#"
package Database;

sub query_data { return "data"; }

# In same file - test both patterns
sub example {
    query_data();              # Unqualified reference
    Database::query_data();    # Qualified reference
}
"#;
    
    server.documents.lock().unwrap().insert(
        "file:///Database.pm".to_string(),
        DocumentState::new(content),
    );
    
    // Test find references for "query_data" - should find both patterns
    let result = server.handle_references(json!({
        "textDocument": {"uri": "file:///Database.pm"},
        "position": {"line": 2, "character": 5}, // On function declaration
        "context": {"includeDeclaration": true}
    }));
    
    assert!(result.is_ok());
    let references = result.unwrap().unwrap();
    let refs_array = references.as_array().unwrap();
    
    // Should find: declaration + unqualified call + qualified call = 3 references
    assert!(refs_array.len() >= 3);
}
```

### Comment Documentation Extraction

The system provides comprehensive comment documentation extraction with the following features:

- **Leading Comments**: Extracts multi-line comments immediately preceding symbol declarations with precise boundary detection
- **Blank Line Handling**: Stops at actual blank lines (not whitespace-only lines) for accurate comment boundaries  
- **Whitespace Resilient**: Handles varying indentation and comment prefixes (`#`, `##`, `###`) with automatic normalization
- **Performance Optimized**: <100¬µs extraction time with pre-allocated string capacity for large comment blocks
- **Unicode Safe**: Proper UTF-8 character boundary handling with support for international comments and emojis
- **Multi-Package Support**: Correct comment extraction across package boundaries with qualified name resolution
- **Edge Case Robust**: Handles empty comments, source boundaries, non-ASCII whitespace, and complex formatting scenarios
- **Method Documentation**: Full support for class methods, subroutines, and variable list declarations
- **Production Testing**: 20 comprehensive test cases covering all edge cases and performance scenarios
- **AST Integration**: Documentation attached to Symbol structs for use across all LSP features with source threading

#### Comment Documentation Examples
```perl
# This documents the function below
# Multiple line comments are supported
# with proper boundary detection
sub documented_function {
    # Internal comment - not documentation
}

### Variable documentation with various comment styles  
   ### Works with extra whitespace and hashes
my $documented_var = 42;

# This will NOT be captured as documentation for foo
# because there's a blank line

sub foo {  # Not documentation
}
```

## Cross-File Reference Handling (*Diataxis: Reference* - Enhanced package-qualified identifier support v0.8.8+)

The v0.8.8+ release includes significant improvements to cross-file reference handling, particularly for package-qualified identifiers and reference deduplication.

### Enhanced Workspace Indexing

The workspace indexing system now provides more accurate cross-file reference tracking:

#### **Improved Reference Deduplication**
```rust
// Enhanced find_refs implementation in workspace_index.rs
pub fn find_refs(&self, key: &SymbolKey) -> Vec<Location> {
    let qualified_name = format!("{}::{}", key.pkg, key.name);
    let mut all_refs = self.find_references(&qualified_name);

    // Critical improvement: Remove the definition from references
    // The caller will include it separately if needed (e.g., for "Go to Definition")
    if let Some(def) = self.find_def(key) {
        all_refs.retain(|loc| !(loc.uri == def.uri && loc.range == def.range));
    }

    // Enhanced deduplication using HashSet for O(n) performance
    let mut seen = HashSet::new();
    all_refs.retain(|loc| seen.insert((loc.uri.clone(), loc.range)));
    
    all_refs
}
```

#### **Package-Qualified Identifier Support**
The system now correctly handles package-qualified identifiers in cross-file scenarios:

**Before v0.8.8:**
- References could include function definitions
- Duplicate entries from dual indexing
- Inconsistent handling of package contexts

**After v0.8.8:**
- Clean separation of references vs definitions
- Intelligent deduplication across qualified/unqualified names
- Consistent package context resolution

#### **LSP Feature Integration**

These improvements directly enhance several LSP features:

**Find All References** (`textDocument/references`):
```rust
// Clean reference lists without definitions
let references = workspace_index.find_refs(&symbol_key);
// References now exclude the definition automatically
```

**Go to Definition** (`textDocument/definition`):
```rust
// Definitions handled separately for accuracy
if let Some(definition) = workspace_index.find_def(&symbol_key) {
    // Definition logic separate from reference finding
}
```

**Workspace Rename** (`workspace/willRename`):
```rust
// More accurate rename operations across qualified calls
let all_occurrences = workspace_index.find_refs(&symbol_key);
// Plus the definition if renaming the symbol itself
if include_definition {
    if let Some(def) = workspace_index.find_def(&symbol_key) {
        all_occurrences.push(def);
    }
}
```

### Development Best Practices

When working with cross-file references in LSP features:

1. **Use Enhanced APIs**: Always use `find_refs()` for references and `find_def()` for definitions
2. **Handle Package Context**: Consider both bare and qualified names when searching
3. **Leverage Deduplication**: The system automatically handles duplicate removal
4. **Separate Concerns**: Keep reference finding separate from definition resolution

### Testing Cross-File Features

```bash
# Test cross-file reference improvements
cargo test -p perl-parser workspace_index_enhanced_deduplication
cargo test -p perl-parser workspace_rename_package_qualified_support

# Integration tests for LSP features
cargo test -p perl-lsp test_find_references_excludes_definitions
cargo test -p perl-lsp test_package_qualified_navigation
```

## Adding New LSP Features

When implementing new LSP features, follow this structure:

1. **Core Implementation** (`/crates/perl-parser/src/`)
   - Add feature module (e.g., `completion.rs`, `code_actions.rs`)
   - Implement provider struct with main logic
   - **Use source-aware constructors** for enhanced documentation support
   - Add to `lib.rs` exports

2. **LSP Server Integration** (`lsp_server.rs`)
   - Add handler method (e.g., `handle_completion`)
   - **Thread source text** through provider constructors using `doc.content`
   - Wire up in main request dispatcher
   - Handle request/response formatting

3. **Testing**
   - Unit tests in the module itself
   - Integration tests in `/tests/lsp_*_tests.rs`
   - **Symbol documentation tests** for comment extraction features
   - User story tests for real-world scenarios

## Testing Procedures (*Diataxis: How-to Guide* - Testing procedures)

### Dual-Scanner Corpus Validation (v0.8.8+)

For comprehensive LSP development testing, use dual-scanner corpus comparison to validate parser behavior:

```bash
# Prerequisites: Install system dependencies
sudo apt-get install libclang-dev  # Ubuntu/Debian
brew install llvm                  # macOS

# Run corpus comparison modes (legacy feature required)
cargo run -p xtask --features legacy -- corpus                          # Corpus vs selected parser (default scanner: v3)
cargo run -p xtask --features legacy -- corpus --scanner both --diagnose # C vs v3 detailed analysis

# Individual scanner validation  
cargo run -p xtask --features legacy -- corpus --scanner c                    # C scanner
cargo run -p xtask --features legacy -- corpus --scanner rust                 # In-crate v2 parser
cargo run -p xtask --features legacy -- corpus --scanner v2-pest-microcrate   # Extracted v2 parser
cargo run -p xtask --features legacy -- corpus --scanner v2-parity --diagnose # v2 parity mode
cargo run -p xtask --features legacy -- corpus --scanner v3                   # V3 native parser

# Diagnostic analysis for parser differences
cargo run -p xtask --features legacy -- corpus --diagnose  # Analyze first failing test
cargo run -p xtask --features legacy -- corpus --test      # Test simple expressions
```

### Understanding Scanner Mismatch Reports (*Diataxis: Reference* - Output interpretation)

When scanner outputs differ (primarily legacy testing since C scanner now delegates to Rust), the system provides detailed analysis:
```
üîÄ Scanner mismatches:
   expressions.txt: binary_expression_precedence

üîç STRUCTURAL ANALYSIS:
C scanner nodes: 15
Rust scanner nodes: 14
‚ùå Nodes missing in Rust output:
  - precedence_node
‚ûï Extra nodes in Rust output:  
  - simplified_expression
```

Use this information to:
1. **Identify parsing differences** between C and Rust implementations
2. **Validate LSP behavior** across different parser backends  
3. **Track parser development** and feature parity
4. **Debug structural inconsistencies** in AST generation

## Code Actions and Refactoring

The refactoring system has two layers:

1. **Base Code Actions** (`code_actions.rs`)
   - Quick fixes for diagnostics
   - Simple refactorings
   - Integration with diagnostics

2. **Enhanced Refactorings** (`code_actions_enhanced.rs`)
   - Extract variable/subroutine
   - Loop conversions
   - Advanced pattern matching
   - Smart naming and formatting preservation

3. **Import Optimization** (`import_optimizer.rs` + integration)
   - Remove unused imports and symbols
   - Add missing imports via Module::symbol detection  
   - Remove duplicate imports and consolidate
   - Alphabetical sorting and clean formatting
   - LSP code action integration with "Organize Imports"

### Import Optimization Development Pattern (*Diataxis: How-to* - Import feature development)

Implementing import optimization features follows this pattern:

#### 1. Core Analysis Engine (`import_optimizer.rs`)
```rust
pub struct ImportOptimizer {
    // Stateless analyzer - no persistent state for thread safety
}

impl ImportOptimizer {
    pub fn analyze_content(&self, content: &str) -> Result<ImportAnalysis, String> {
        // Parse import statements using regex
        let imports = self.extract_imports(content)?;
        
        // Analyze usage patterns 
        let unused = self.find_unused_imports(&imports, content);
        let duplicates = self.find_duplicate_imports(&imports);
        let missing = self.find_missing_imports(content);
        
        Ok(ImportAnalysis {
            imports,
            unused_imports: unused,
            duplicate_imports: duplicates,
            missing_imports: missing,
            organization_suggestions: self.generate_suggestions(&imports),
        })
    }
    
    pub fn generate_edits(&self, content: &str, analysis: &ImportAnalysis) -> Vec<TextEdit> {
        // Generate LSP-compatible text edits for optimization
        let optimized_imports = self.generate_optimized_imports(analysis);
        self.create_replacement_edits(content, analysis, &optimized_imports)
    }
}
```

#### 2. Code Actions Integration (`code_actions.rs`)
```rust
// Integration point in main code actions provider
fn optimize_imports(&self) -> Option<CodeAction> {
    let optimizer = ImportOptimizer::new();
    let analysis = optimizer.analyze_content(&self.source).ok()?;
    
    // Skip if no optimizations needed
    if analysis.unused_imports.is_empty() 
        && analysis.duplicate_imports.is_empty()
        && analysis.missing_imports.is_empty() 
    {
        return None;
    }
    
    let edits = optimizer.generate_edits(&self.source, &analysis);
    Some(CodeAction {
        title: "Organize imports".to_string(),
        kind: CodeActionKind::SourceOrganizeImports,
        diagnostics: Vec::new(),
        edit: CodeActionEdit { changes: edits },
        is_preferred: false,
    })
}

// Called automatically in main code actions handler
pub fn get_code_actions(&self, ast: &Node, range: (usize, usize), diagnostics: &[Diagnostic]) -> Vec<CodeAction> {
    let mut actions = Vec::new();
    
    // Add diagnostic-based quick fixes...
    
    // Add import optimization (always available)
    if let Some(import_action) = self.optimize_imports() {
        actions.push(import_action);
    }
    
    actions
}
```

#### 3. LSP Server Registration (`lsp_server.rs`)
```rust
// Capability registration for import optimization
fn handle_initialize(&self, _params: Option<Value>) -> Result<Option<Value>, JsonRpcError> {
    Ok(Some(json!({
        "capabilities": {
            "codeActionProvider": {
                "codeActionKinds": [
                    "quickfix",
                    "refactor",
                    "refactor.extract",
                    "source.organizeImports", // Import optimization
                ]
            }
        }
    })))
}

// Code action handler with import optimization 
fn handle_code_action(&self, params: Option<Value>) -> Result<Option<Value>, JsonRpcError> {
    let params: CodeActionParams = serde_json::from_value(params?)?;
    let doc = self.get_document(&params.text_document.uri)?;
    
    let provider = CodeActionsProvider::new(doc.content.clone());
    let actions = provider.get_code_actions(
        &doc.ast,
        (params.range.start, params.range.end), 
        &diagnostics
    );
    
    Ok(Some(json!(actions)))
}
```

#### 4. Testing Pattern for Import Features
```rust
#[cfg(test)]
mod import_tests {
    use super::*;
    
    #[test]
    fn test_import_optimization_integration() {
        let source = r#"
use strict;
use warnings;
use Data::Dumper;  # Used
use JSON;          # Unused
use List::Util qw(first max min);  # Partially used

my @nums = (1, 2, 3);
print "Max: " . max(@nums) . "\n";
print Dumper(\@nums);
"#;
        
        // Test analysis
        let optimizer = ImportOptimizer::new();
        let analysis = optimizer.analyze_content(source).unwrap();
        
        assert!(analysis.unused_imports.iter().any(|u| u.module == "JSON"));
        assert!(analysis.unused_imports.iter().any(|u| u.module == "List::Util" && u.symbols.contains(&"first".to_string())));
        
        // Test code action integration
        let provider = CodeActionsProvider::new(source.to_string());
        let actions = provider.get_code_actions(&ast, (0, source.len()), &[]);
        
        let import_action = actions.iter()
            .find(|a| matches!(a.kind, CodeActionKind::SourceOrganizeImports))
            .expect("Should have import optimization action");
            
        assert_eq!(import_action.title, "Organize imports");
        assert!(!import_action.edit.changes.is_empty());
    }
    
    #[test] 
    fn test_lsp_import_optimization_e2e() {
        // End-to-end LSP server test
        let mut server = create_test_server();
        initialize_server(&mut server);
        
        open_document(&mut server, "file:///test.pl", source_with_import_issues);
        
        let response = send_request(&mut server, "textDocument/codeAction", Some(json!({
            "textDocument": { "uri": "file:///test.pl" },
            "range": { "start": { "line": 0, "character": 0 }, "end": { "line": 10, "character": 0 } },
            "context": { "diagnostics": [] }
        })));
        
        let actions = response["result"].as_array().unwrap();
        let import_action = actions.iter()
            .find(|a| a["kind"] == "source.organizeImports")
            .expect("Should have import optimization");
            
        assert_eq!(import_action["title"], "Organize imports");
    }
}
```

### Generic Refactoring Pattern
```rust
// In code_actions_enhanced.rs
fn your_refactoring(&self, node: &Node) -> Option<CodeAction> {
    // 1. Check if refactoring applies
    // 2. Generate new code
    // 3. Return CodeAction with TextEdits
}
```

### Enhanced executeCommand Integration ‚≠ê **NEW: Issue #145** (*Diataxis: How-to Guide* - executeCommand development patterns)

The LSP server now supports comprehensive executeCommand functionality with robust error handling and tool integration patterns.

#### executeCommand Provider Development Pattern

**Core Provider Architecture** (*Diataxis: How-to* - Building executeCommand providers):
```rust
// In execute_command.rs - Central command dispatcher pattern
pub struct ExecuteCommandProvider {
    parser: Arc<dyn Parser>,
    document_manager: Arc<DocumentManager>,
    workspace_index: Option<Arc<WorkspaceIndex>>,
}

impl ExecuteCommandProvider {
    pub fn execute_command(&self, command: &str, arguments: Vec<Value>)
        -> Result<Value, JsonRpcError> {

        match command {
            "perl.runCritic" => self.execute_perl_critic(arguments),
            "perl.runTests" => self.execute_tests(arguments),
            "perl.runFile" => self.execute_file(arguments),
            "perl.debugTests" => self.execute_debug_tests(arguments),
            _ => Err(JsonRpcError::method_not_found())
        }
    }
}
```

**Dual Analyzer Strategy Pattern** (*Diataxis: How-to* - Tool integration with fallback):
```rust
// perl.runCritic implementation with graceful degradation
impl ExecuteCommandProvider {
    fn execute_perl_critic(&self, arguments: Vec<Value>) -> Result<Value, JsonRpcError> {
        let file_path = self.extract_file_path(&arguments)?;

        // Try external perlcritic first (preferred)
        match self.run_external_perlcritic(&file_path) {
            Ok(external_result) => {
                Ok(serde_json::to_value(CriticResult::External(external_result))?)
            },
            Err(_) => {
                // Fallback to built-in analyzer for 100% availability
                let builtin_result = self.run_builtin_analyzer(&file_path)?;
                Ok(serde_json::to_value(CriticResult::Builtin(builtin_result))?)
            }
        }
    }

    fn run_external_perlcritic(&self, file_path: &str) -> Result<Vec<Violation>, String> {
        // External tool integration with timeout and error handling
        let output = Command::new("perlcritic")
            .arg("--verbose=8")
            .arg(file_path)
            .timeout(Duration::from_secs(30))
            .output()
            .map_err(|e| format!("Failed to execute perlcritic: {}", e))?;

        self.parse_perlcritic_output(&output.stdout)
    }

    fn run_builtin_analyzer(&self, file_path: &str) -> Result<Vec<Violation>, String> {
        // Built-in analyzer using AST parsing
        let content = std::fs::read_to_string(file_path)?;
        let ast = self.parser.parse(&content)?;

        let analyzer = BuiltInCriticAnalyzer::new();
        analyzer.analyze(&ast, &content)
    }
}
```

**Error Handling Pattern** (*Diataxis: How-to* - Robust error responses):
```rust
// Structured error responses with user-friendly messages
impl ExecuteCommandProvider {
    fn handle_execution_error(&self, command: &str, error: &str) -> JsonRpcError {
        match command {
            "perl.runCritic" => JsonRpcError::new(
                -32603, // Internal error
                format!("Code analysis failed: {}", error),
                Some(json!({
                    "fallback_available": true,
                    "suggestion": "Ensure perlcritic is installed or use built-in analyzer",
                    "command": command,
                    "recovery_action": "install_perlcritic"
                }))
            ),
            "perl.runTests" => JsonRpcError::new(
                -32603,
                format!("Test execution failed: {}", error),
                Some(json!({
                    "suggestion": "Check test file syntax and dependencies",
                    "command": command
                }))
            ),
            _ => JsonRpcError::internal_error()
        }
    }
}
```

#### LSP Server Integration Pattern

**Server Handler Integration** (*Diataxis: How-to* - Wiring executeCommand to LSP protocol):
```rust
// In lsp_server.rs - Protocol integration
impl LspServer {
    fn handle_execute_command(&mut self, params: ExecuteCommandParams)
        -> Result<Option<Value>, JsonRpcError> {

        // Validate command is supported
        if !SUPPORTED_COMMANDS.contains(&params.command.as_str()) {
            return Err(JsonRpcError::method_not_found());
        }

        // Execute with provider
        let provider = ExecuteCommandProvider::new(
            self.parser.clone(),
            self.documents.clone(),
            self.workspace_index.clone()
        );

        provider.execute_command(&params.command, params.arguments)
            .map(Some)
    }

    // Capability advertisement
    fn get_execute_command_capabilities() -> ExecuteCommandOptions {
        ExecuteCommandOptions {
            commands: SUPPORTED_COMMANDS.iter().map(|s| s.to_string()).collect()
        }
    }
}

// Supported commands registry
pub static SUPPORTED_COMMANDS: &[&str] = &[
    "perl.runTests",
    "perl.runFile",
    "perl.runTestSub",
    "perl.debugTests",
    "perl.runCritic",  // ‚≠ê NEW: Issue #145
];
```

### Advanced Code Actions Development Patterns ‚≠ê **NEW: Issue #145**

Enhanced code actions now provide sophisticated refactoring with AST integration and cross-file impact analysis.

#### Enhanced Provider Architecture Pattern

**Multi-tier Code Action Provider** (*Diataxis: How-to* - Advanced refactoring architecture):
```rust
// In code_actions_enhanced.rs - Sophisticated refactoring provider
pub struct EnhancedCodeActionsProvider {
    ast: Node,
    source: String,
    document_uri: String,
    workspace_index: Option<Arc<WorkspaceIndex>>,
    performance_cache: Arc<Mutex<CodeActionCache>>,
}

impl EnhancedCodeActionsProvider {
    pub fn get_code_actions(&self, range: Range, context: &CodeActionContext)
        -> Vec<CodeAction> {

        let mut actions = Vec::new();

        // Check cache first for performance
        if let Some(cached) = self.get_cached_actions(&range, context) {
            return cached;
        }

        // AST-aware refactoring analysis
        let node_at_range = self.find_node_at_range(&range);

        // Extract operations (RefactorExtract)
        actions.extend(self.get_extract_actions(&node_at_range));

        // Import management (SourceOrganizeImports)
        actions.extend(self.get_import_actions());

        // Code quality improvements (RefactorRewrite)
        actions.extend(self.get_modernization_actions(&node_at_range));

        // Cache results for performance
        self.cache_actions(&range, context, &actions);

        actions
    }
}
```

**Extract Variable Pattern with Intelligent Naming**:
```rust
// Smart variable extraction with scope analysis
fn create_extract_variable_action(&self, node: &Node) -> Option<CodeAction> {
    // Validate extraction candidate
    if !self.is_extractable_expression(node) {
        return None;
    }

    // Generate intelligent variable name
    let suggested_name = self.suggest_variable_name(node);
    let extraction_scope = self.calculate_extraction_scope(node);

    // Ensure no name conflicts in scope
    let final_name = self.resolve_name_conflicts(&suggested_name, &extraction_scope);

    // Generate workspace edit
    let edit = self.create_extract_variable_edit(node, &final_name, &extraction_scope);

    Some(CodeAction {
        title: format!("Extract variable '{}'", final_name),
        kind: Some(CodeActionKind::REFACTOR_EXTRACT),
        edit: Some(edit),
        is_preferred: Some(self.calculate_preference_score(node) > 0.8),
        data: Some(json!({
            "refactoring_type": "extract_variable",
            "suggested_name": final_name,
            "scope": extraction_scope.to_string()
        }))
    })
}

// Intelligent naming based on context
fn suggest_variable_name(&self, node: &Node) -> String {
    match node.kind() {
        "function_call" => self.suggest_from_function_call(node),
        "binary_expression" => self.suggest_from_operation(node),
        "string_literal" => "text".to_string(),
        "numeric_literal" => "value".to_string(),
        _ => "extracted_value".to_string()
    }
}
```

**Cross-file Extract Subroutine with Dual Indexing**:
```rust
// Advanced subroutine extraction with workspace awareness
fn create_extract_subroutine_action(&self, node: &Node) -> Option<CodeAction> {
    let params = self.detect_parameters(node);
    let return_values = self.analyze_return_flow(node);
    let subroutine_name = self.suggest_subroutine_name(node);

    // Cross-file impact analysis using dual indexing
    let current_package = self.get_current_package();
    let qualified_name = format!("{}::{}", current_package, subroutine_name);

    // Check for naming conflicts across workspace
    if let Some(workspace_index) = &self.workspace_index {
        if workspace_index.has_symbol(&qualified_name) {
            return None; // Avoid conflicts
        }
    }

    // Generate subroutine with proper signatures
    let subroutine_code = self.generate_subroutine_code(
        &subroutine_name,
        &params,
        &return_values,
        node
    );

    let insertion_point = self.find_subroutine_insertion_point();
    let call_replacement = self.generate_subroutine_call(&subroutine_name, &params);

    // Create workspace edit with dual indexing updates
    let mut edit = WorkspaceEdit::default();
    edit.changes = Some(hashmap! {
        self.document_uri.clone() => vec![
            TextEdit::new(node.range(), call_replacement),
            TextEdit::new(insertion_point, subroutine_code),
        ]
    });

    Some(CodeAction {
        title: format!("Extract subroutine '{}'", subroutine_name),
        kind: Some(CodeActionKind::REFACTOR_EXTRACT),
        edit: Some(edit),
        is_preferred: Some(params.len() <= 3), // Prefer simple extractions
    })
}
```

#### Performance Optimization Patterns

**Multi-tier Caching Strategy** (*Diataxis: How-to* - Code action performance):
```rust
// High-performance caching with incremental invalidation
pub struct CodeActionCache {
    lru_cache: LruCache<CacheKey, Vec<CodeAction>>,  // 50MB limit
    ast_fingerprints: HashMap<String, u64>,          // AST change detection
    file_timestamps: HashMap<String, SystemTime>,    // File modification tracking
}

impl CodeActionCache {
    fn get_cached_actions(&mut self, uri: &str, range: &Range,
                         context: &CodeActionContext) -> Option<Vec<CodeAction>> {

        let cache_key = CacheKey::new(uri, range, context);

        // Check if cache is still valid
        if self.is_cache_valid(uri, &cache_key) {
            return self.lru_cache.get(&cache_key).cloned();
        }

        None
    }

    fn cache_actions(&mut self, uri: &str, range: &Range,
                    context: &CodeActionContext, actions: &[CodeAction]) {

        let cache_key = CacheKey::new(uri, range, context);
        self.lru_cache.put(cache_key, actions.to_vec());

        // Update tracking information
        self.file_timestamps.insert(uri.to_string(), SystemTime::now());
    }
}
```

The enhanced executeCommand and code actions development patterns provide a comprehensive framework for building LSP features with robust error handling and user experience characteristics.

## Testing LSP Features

### Test Infrastructure (PR #140) (v0.8.8+)
The project includes test infrastructure with significant performance optimizations for test reliability:

**Performance Achievements (PR #140)**:
- **LSP behavioral tests**: 1560s+ ‚Üí 0.31s
- **User story tests**: 1500s+ ‚Üí 0.32s
- **Individual workspace tests**: 60s+ ‚Üí 0.26s
- **Overall test suite**: 60s+ ‚Üí <10s
- **CI reliability**: 100% pass rate (was ~55% due to timeouts)

**Enhanced Async LSP Harness** (`tests/support/lsp_harness.rs`):
- **Thread-safe Communication**: Uses mpsc channels for non-blocking server communication
- **Adaptive Timeout Support**: Multi-tier timeout scaling (200ms-500ms LSP harness)
- **Real JSON-RPC Protocol**: Tests actual protocol compliance with enhanced performance
- **Background Processing**: Server runs in separate thread with optimized idle detection
- **Intelligent Symbol Waiting**: Exponential backoff with mock responses
- **Enhanced Test Harness**: Graceful degradation for CI environments
- **Optimized Idle Detection**: 1000ms ‚Üí 200ms cycles (**5x improvement**)

### Performance Testing Configuration (PR #140) (v0.8.8+) (**Diataxis: How-to Guide** - Performance testing)

The PR #140 enhancements deliver comprehensive performance optimizations:

**Key Optimization Components**:
- **Adaptive Timeout Configuration**: Thread-aware timeout scaling
- **Intelligent Symbol Waiting**: Exponential backoff with fast fallback  
- **Optimized Idle Detection**: 1000ms ‚Üí 200ms cycles (5x improvement)
- **Enhanced Test Harness**: Mock responses and graceful degradation
- **Thread-Aware Sleep Scaling**: Sophisticated concurrency management

#### LSP_TEST_FALLBACKS Environment Variable (**NEW**)

**Purpose**: Enable fast testing mode for CI and development environments

**Configuration**:
```bash
# Enable fast testing mode (reduces test timeouts by ~75%)
export LSP_TEST_FALLBACKS=1

# Performance characteristics:
# - Request timeout: 500ms (vs 2000ms)
# - Wait for idle: 50ms (vs 2000ms)
# - Symbol polling: single 200ms attempt (vs progressive backoff)
# - Result: test_completion_detail_formatting: 60s+ ‚Üí 0.26s (99.5% improvement)
```

**Usage Examples**:
```bash
# Run all LSP tests in fast mode
LSP_TEST_FALLBACKS=1 cargo test -p perl-lsp

# Combine threading control with fast mode for optimal CI reliability (v0.8.8+)
RUST_TEST_THREADS=2 LSP_TEST_FALLBACKS=1 cargo test -p perl-lsp -- --test-threads=2

# Performance testing with enhanced test harness (PR #140)
RUST_TEST_THREADS=2 cargo test -p perl-lsp --test lsp_behavioral_tests     # 0.31s (was 1560s+)
RUST_TEST_THREADS=2 cargo test -p perl-lsp --test lsp_full_coverage_user_stories  # 0.32s (was 1500s+)

# Traditional performance-sensitive tests with controlled threading
RUST_TEST_THREADS=2 LSP_TEST_FALLBACKS=1 cargo test -p perl-lsp test_completion_detail_formatting -- --test-threads=2
RUST_TEST_THREADS=2 LSP_TEST_FALLBACKS=1 cargo test -p perl-lsp test_workspace_symbol_search -- --test-threads=2

# Validate workspace builds quickly
LSP_TEST_FALLBACKS=1 cargo check --workspace
```

#### Timeout Configuration Modes (**Diataxis: Reference**)

**Adaptive Mode (PR #140)** - Enhanced adaptive configuration:
```rust
// Adaptive timeout configuration with exponential backoff
fn get_adaptive_timeout() -> Duration {
    let thread_count = std::env::var("RUST_TEST_THREADS")
        .ok()
        .and_then(|s| s.parse::<usize>().ok())
        .unwrap_or(4);

    match thread_count {
        0..=2 => Duration::from_millis(500), // High contention: longer timeout
        3..=4 => Duration::from_millis(300), // Medium contention
        _ => Duration::from_millis(200),     // Low contention: shorter timeout
    }
}

// Optimized idle detection (5x improvement)
let idle_wait = Duration::from_millis(200);     // Was 1000ms, now 200ms
```

**Traditional Production Mode** (default - comprehensive testing):
```rust
// Default timeouts for thorough testing
let timeout = Duration::from_secs(2);           // Request timeout
let idle_wait = Duration::from_secs(2);         // Wait for idle
let symbol_budget = Duration::from_secs(10);    // Symbol polling
```

**Fast Mode** (LSP_TEST_FALLBACKS=1 - optimized for speed):
```rust
// Optimized timeouts for CI/development
let timeout = Duration::from_millis(500);       // 75% reduction
let idle_wait = Duration::from_millis(50);      // 97.5% reduction  
let symbol_check = Duration::from_millis(200);  // Single attempt
```

#### Performance Validation Results

**Before Optimization**:
- `test_completion_detail_formatting`: >60 seconds (often timeout)
- Workspace symbol tests: Often exceed CI limits
- Test suite runtime: 5-10 minutes

**After Optimization (v0.8.8)**:
- `test_completion_detail_formatting`: 0.26 seconds (99.5% faster)
- All tests pass with `LSP_TEST_FALLBACKS=1`: <10 seconds total
- Test suite runtime: <1 minute in fast mode
- Zero functional regressions: All tests maintain identical behavior

**Assertion Helpers** (`tests/support/mod.rs`):
- **Deep Validation**: All LSP responses are validated for proper structure
- **Meaningful Errors**: Clear error messages for debugging test failures
- **No Tautologies**: All assertions actually validate response content

### Using the Async Test Harness
```rust
// Create harness with automatic server initialization
let mut harness = LspHarness::new();
harness.initialize(None)?;

// Test with custom timeout (useful for slow operations)
let response = harness.request_with_timeout(
    "textDocument/completion", 
    params, 
    Duration::from_millis(500)
)?;

// Test notifications (like diagnostics)
harness.open_document("file:///test.pl", "my $var = 42;");
let notifications = harness.drain_notifications(
    Some("textDocument/publishDiagnostics"), 
    1000  // 1 second timeout
);

// Test bounded operations (prevents infinite hangs)
let definition = harness.request_with_timeout(
    "textDocument/definition",
    definition_params,
    Duration::from_millis(500)
)?;
```

### Test Commands
```bash
# Unit tests
cargo test -p perl-parser your_feature

# LSP API contract tests (async harness)
cargo test -p perl-lsp lsp_api_contracts

# Integration tests with timeout handling
cargo test -p perl-parser lsp_your_feature_tests

# Manual testing with real protocol

# Test external dependency robustness
cargo test -p perl-lsp --test lsp_comprehensive_e2e_test test_e2e_document_formatting  # Passes with or without perltidy
cargo test -p perl-lsp --test lsp_perltidy_test                                         # Tests capability advertising
echo '{"jsonrpc":"2.0","method":"your_method",...}' | perl-lsp --stdio

# Run comprehensive E2E tests (100% passing as of v0.8.6)
cargo test -p perl-parser lsp_comprehensive_e2e_test

# LSP testing with enhanced harness (PR #140)
cargo test -p perl-lsp --test lsp_behavioral_tests     # 0.31s (was 1560s+)
cargo test -p perl-lsp --test lsp_full_coverage_user_stories  # 0.32s (was 1500s+)

# Run all LSP tests with async harness (48+ tests, <10s total)
cargo test -p perl-lsp
```

## Enhanced Position Tracking Development (v0.8.7+)

The enhanced position tracking system provides accurate line/column mapping for LSP compliance:

### Using PositionTracker in Parser Context
```rust
use crate::parser_context::ParserContext;

// Create parser with automatic position tracking
let ctx = ParserContext::new(source);

// Access accurate token positions
let token = ctx.current_token().unwrap();
let range = token.range();
println!("Token at line {}, column {}", range.start.line, range.start.column);
```

### Position Tracking API Reference
```rust
// Core PositionTracker methods
impl PositionTracker {
    /// Create from source text with line start caching
    pub fn new(source: String) -> Self;
    
    /// Convert byte offset to Position with UTF-16 support  
    pub fn byte_to_position(&self, byte_offset: usize) -> Position;
}

// LineStartsCache for O(log n) lookups
impl LineStartsCache {
    /// Build cache with CRLF/LF/CR line ending support
    pub fn new(text: &str) -> Self;
    
    /// Convert byte offset to (line, utf16_column)
    pub fn offset_to_position(&self, text: &str, offset: usize) -> (u32, u32);
}
```

## Error Recovery and Fallback Mechanisms (*Diataxis: Explanation* - Enhanced reliability architecture v0.8.8+)

The LSP server includes comprehensive, production-tested fallback mechanisms that ensure 99.9% feature availability even during parser failures, incomplete code, or AST unavailability. The v0.8.8+ release significantly enhances these systems with intelligent text-based analysis and robust error handling.

### Three-Tier Reliability Architecture (*Diataxis: Explanation* - Understanding the reliability strategy)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    Primary      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   AST-Based     ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí ‚îÇ   Full Feature  ‚îÇ
‚îÇ   Analysis      ‚îÇ                 ‚îÇ   Set Available ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚îÇ Degradation
         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    Secondary    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Text-Based    ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí ‚îÇ   Core Features ‚îÇ
‚îÇ   Fallbacks     ‚îÇ                 ‚îÇ   Maintained    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚îÇ Final Safety
         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    Tertiary     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Safe Error    ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí ‚îÇ   Graceful      ‚îÇ
‚îÇ   Responses     ‚îÇ                 ‚îÇ   Error Handling‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Core Fallback Mechanisms (*Diataxis: Reference* - Complete fallback specification)

#### 1. Enhanced Workspace Symbol Fallback (*Diataxis: Reference* - v0.8.8+)

**Comprehensive Text-Based Symbol Detection**:
```rust
// Multi-pattern symbol extraction with improved accuracy
fn extract_text_based_symbols(&self, text: &str, uri: &str, query: &str) -> Vec<LspWorkspaceSymbol> {
    let mut symbols = Vec::new();
    let query_lower = query.to_lowercase();
    
    // Subroutine detection with method context
    for (line_num, line) in text.lines().enumerate() {
        // Standard subroutines: sub name { ... }
        if let Some(cap) = self.sub_regex.captures(line) {
            if let Some(name) = cap.get(1) {
                let symbol_name = name.as_str().to_string();
                if symbol_name.to_lowercase().contains(&query_lower) {
                    symbols.push(LspWorkspaceSymbol {
                        name: symbol_name,
                        kind: 12, // Function
                        location: self.create_location(uri, line_num, line),
                    });
                }
            }
        }
        
        // Package declarations with namespace support
        if let Some(cap) = self.package_regex.captures(line) {
            if let Some(name) = cap.get(1) {
                let symbol_name = name.as_str().to_string();
                if symbol_name.to_lowercase().contains(&query_lower) {
                    symbols.push(LspWorkspaceSymbol {
                        name: symbol_name,
                        kind: 4, // Module
                        location: self.create_location(uri, line_num, line),
                    });
                }
            }
        }
    }
    
    symbols
}
```

**Enhanced Features**:
- ‚úÖ Improved regex patterns with reduced false positives
- ‚úÖ Context-aware symbol classification
- ‚úÖ Enhanced package and module detection
- ‚úÖ Method vs subroutine differentiation
- ‚úÖ Namespace-aware symbol resolution

#### 2. Advanced Code Lens Fallback (*Diataxis: Reference* - v0.8.8+)

**Intelligent Reference Counting with Method Detection**:
```rust
fn extract_text_based_code_lenses(&self, text: &str, _uri: &str) -> Vec<Value> {
    let mut lenses = Vec::new();
    let lines: Vec<&str> = text.lines().collect();
    
    for (line_num, line) in lines.iter().enumerate() {
        if let Some(cap) = self.sub_regex.captures(line) {
            if let Some(name_match) = cap.get(1) {
                let sub_name = name_match.as_str();
                
                // Enhanced reference counting with method call detection
                let method_refs = self.count_method_references(text, sub_name);
                let function_refs = self.count_function_references(text, sub_name);
                let total_refs = method_refs + function_refs;
                
                // Enhanced lens with detailed breakdown
                lenses.push(json!({
                    "range": {
                        "start": {"line": line_num, "character": 0},
                        "end": {"line": line_num, "character": line.len()}
                    },
                    "command": {
                        "title": format!("{} reference{} ({} method, {} function)", 
                                       total_refs, 
                                       if total_refs == 1 { "" } else { "s" },
                                       method_refs,
                                       function_refs),
                        "command": "perl.showReferences",
                        "arguments": [sub_name, total_refs]
                    }
                }));
            }
        }
    }
    
    lenses
}
```

**Enhanced Features**:
- ‚úÖ Method call vs function call differentiation  
- ‚úÖ More accurate reference counting patterns
- ‚úÖ Detailed reference breakdown in lens titles
- ‚úÖ Better handling of complex call patterns

#### 3. Robust Document Symbol Fallback (*Diataxis: Reference* - v0.8.8+)

**Hierarchical Symbol Extraction with Improved Accuracy**:
```rust
fn extract_symbols_fallback(&self, content: &str) -> Vec<Value> {
    let mut symbols = Vec::new();
    let lines: Vec<&str> = content.lines().collect();
    let mut current_package = None;
    
    for (i, line) in lines.iter().enumerate() {
        let trimmed = line.trim();
        
        // Enhanced package detection with version support
        if let Some(cap) = self.enhanced_package_regex.captures(line) {
            if let Some(name) = cap.get(1) {
                let package_name = name.as_str();
                current_package = Some(package_name.to_string());
                
                symbols.push(json!({
                    "name": package_name,
                    "kind": 4, // Module
                    "range": self.line_to_range(i, line),
                    "selectionRange": self.match_to_range(i, name),
                    "children": [] // Will be populated by subroutines
                }));
            }
        }
        
        // Enhanced subroutine detection with package context
        if let Some(cap) = self.enhanced_sub_regex.captures(line) {
            if let Some(name) = cap.get(1) {
                let sub_name = name.as_str();
                let qualified_name = if let Some(ref pkg) = current_package {
                    format!("{}::{}", pkg, sub_name)
                } else {
                    sub_name.to_string()
                };
                
                symbols.push(json!({
                    "name": sub_name,
                    "detail": qualified_name,
                    "kind": 12, // Function
                    "range": self.line_to_range(i, line),
                    "selectionRange": self.match_to_range(i, name)
                }));
            }
        }
        
        // Variable declarations in broader scope
        if let Some(cap) = self.variable_regex.captures(line) {
            if let Some(name) = cap.get(2) { // Skip declaration keyword
                symbols.push(json!({
                    "name": name.as_str(),
                    "kind": 13, // Variable
                    "range": self.line_to_range(i, line),
                    "selectionRange": self.match_to_range(i, name)
                }));
            }
        }
    }
    
    symbols
}
```

#### 4. Enhanced Signature Help Fallback (*Diataxis: Reference* - v0.8.8+)

**Context-Aware Function Detection**:
- Enhanced backward scanning for function context
- Improved method call detection (`$obj->method`, `Class->method`)
- Better parenthesis depth tracking with error recovery
- Support for complex function call patterns
- Fallback signatures for unknown functions with parameter hints

#### 5. Advanced Folding Range Fallback (*Diataxis: Reference* - v0.8.8+)

**Multi-Pattern Folding Detection**:
```rust
fn extract_folding_fallback(&self, content: &str) -> Vec<Value> {
    let mut ranges = Vec::new();
    let lines: Vec<&str> = content.lines().collect();
    
    // Enhanced brace tracking with error recovery
    let mut brace_stack = Vec::new();
    let mut in_pod = false;
    let mut pod_start = 0;
    
    for (i, line) in lines.iter().enumerate() {
        let trimmed = line.trim();
        
        // Enhanced POD detection
        if trimmed.starts_with("=") && !in_pod {
            in_pod = true;
            pod_start = i;
        } else if trimmed == "=cut" && in_pod {
            in_pod = false;
            ranges.push(json!({
                "startLine": pod_start,
                "endLine": i,
                "kind": "comment"
            }));
        }
        
        // Improved brace handling with error recovery
        if !in_pod {
            self.process_brace_folding(trimmed, i, &mut brace_stack, &mut ranges);
        }
        
        // Enhanced subroutine folding
        if let Some(sub_start) = self.detect_subroutine_start(line, i) {
            if let Some(sub_end) = self.find_subroutine_end(&lines, i + 1) {
                ranges.push(json!({
                    "startLine": sub_start,
                    "endLine": sub_end,
                    "kind": "region"
                }));
            }
        }
    }
    
    ranges
}
```

#### 6. Production-Stable Enhanced Scope Analysis (*Diataxis: Reference* - v0.8.7+)

**Industry-Leading Variable Resolution with Hash Context Detection**:
- **Advanced Variable Resolution Patterns**: Hash access (`$hash{key}` ‚Üí `%hash`), array access (`$array[idx]` ‚Üí `@array`)  
- **Hash Key Context Detection** - Comprehensive undefined variable detection under `use strict`:
  - Hash subscripts: `$hash{bareword_key}` - O(depth) performance with safety limits
  - Hash literals: `{ key => value, another_key => value2 }` - all contexts supported
  - Hash slices: `@hash{key1, key2, key3}` - array-based key detection
  - Nested hash access: `$hash{level1}{level2}{level3}` - deep nesting support
- Enhanced scope analysis with production-proven `is_in_hash_key_context()` method
- Context-aware bareword detection with 99.8% accuracy
- **38 comprehensive test cases** with full edge case coverage

### Enhanced Error Handling Patterns (*Diataxis: How-to* - Implementing robust error handling)

#### Pattern 1: Graceful Degradation with Logging

```rust
impl LspServer {
    fn handle_feature_with_fallback<T>(
        &self,
        primary_handler: impl FnOnce() -> Result<T, Box<dyn std::error::Error>>,
        fallback_handler: impl FnOnce() -> T,
        feature_name: &str,
    ) -> T {
        match primary_handler() {
            Ok(result) => result,
            Err(e) => {
                eprintln!("Primary {} handler failed: {}. Using fallback.", feature_name, e);
                // Optional: Log to LSP client for debugging
                self.log_to_client(&format!("Fallback activated for {}: {}", feature_name, e));
                fallback_handler()
            }
        }
    }
}
```

#### Pattern 2: Test-Enhanced Fallback Forcing

```rust
// Development and testing pattern for comprehensive fallback validation
fn get_fallback_mode() -> bool {
    std::env::var("LSP_TEST_FALLBACKS").is_ok() || 
    std::env::var("LSP_FORCE_FALLBACKS").is_ok()
}

fn handle_with_test_fallbacks(&self, params: Option<Value>) -> Result<Option<Value>, JsonRpcError> {
    if get_fallback_mode() {
        // Force fallback for testing comprehensive coverage
        return Ok(Some(self.extract_fallback_result(params)));
    }
    
    // Normal production path with automatic fallback
    self.handle_primary_path(params)
        .or_else(|_| Ok(Some(self.extract_fallback_result(params))))
}
```

### Performance Impact and Monitoring (*Diataxis: Reference* - Fallback performance characteristics)

#### Fallback Performance Metrics (v0.8.8+)

| Feature Type | AST Success | Text Fallback | Performance Impact | Accuracy |
|-------------|-------------|---------------|-------------------|----------|
| Workspace Symbols | 1.2ms | 4.5ms | +275% | 95% ‚Üí 85% |
| Document Symbols | 0.8ms | 2.1ms | +160% | 98% ‚Üí 90% |
| Code Lens | 0.5ms | 1.8ms | +260% | 99% ‚Üí 88% |
| Folding Ranges | 0.3ms | 1.1ms | +267% | 99% ‚Üí 92% |
| Signature Help | 0.2ms | 0.7ms | +250% | 95% ‚Üí 80% |

#### Memory Usage Optimization

- **AST Mode**: 2.1MB average (500-line files)
- **Fallback Mode**: 850KB average (-60% memory usage)
- **Regex Compilation**: 120KB one-time overhead per pattern set
- **Cache Efficiency**: 85-95% hit rate maintained during fallbacks

### Testing Fallback Reliability (*Diataxis: How-to* - Comprehensive fallback testing)

#### Comprehensive Fallback Test Suite

```rust
#[cfg(test)]
mod fallback_tests {
    use super::*;
    
    #[test]
    fn test_comprehensive_fallback_scenarios() {
        let test_cases = vec![
            ("syntax_error.pl", "sub broken { syntax error here"),
            ("partial_ast.pl", "sub incomplete {"),
            ("complex_nested.pl", include_str!("test_files/nested_structure.pl")),
        ];
        
        for (name, content) in test_cases {
            // Test with AST unavailable
            let mut server = LspServer::new();
            let mut doc = DocumentState::new(content);
            doc.ast = None; // Force fallback
            
            // Verify all features work in fallback mode
            assert!(server.extract_text_based_symbols(content, name, "").len() > 0);
            assert!(server.extract_text_based_code_lenses(content, name).len() >= 0);
            assert!(server.extract_folding_fallback(content).len() >= 0);
            
            println!("‚úÖ Fallback tests passed for {}", name);
        }
    }
    
    #[test]
    fn test_fallback_performance_requirements() {
        let content = include_str!("../test_files/large_perl_file.pl"); // 1000+ lines
        let start = Instant::now();
        
        let server = LspServer::new();
        let symbols = server.extract_text_based_symbols(content, "large.pl", "test");
        
        let duration = start.elapsed();
        assert!(duration.as_millis() < 50, "Fallback should complete within 50ms for large files");
        assert!(!symbols.is_empty(), "Should extract symbols even from complex files");
    }
}
```

### Production Benefits and Reliability (*Diataxis: Explanation* - Understanding the reliability improvements)

#### Enhanced User Experience

1. **99.9% Feature Availability**: Core LSP features remain functional during any parser state
2. **Transparent Fallbacks**: Users experience consistent functionality without visible degradation
3. **Predictable Performance**: Known response time characteristics in all scenarios
4. **Enhanced Debugging**: Clear logging when fallbacks activate for development scenarios

#### Developer Experience Improvements

1. **Comprehensive Testing**: All fallback paths are thoroughly tested and validated
2. **Performance Monitoring**: Built-in performance tracking for fallback activation
3. **Debugging Support**: Detailed error context and fallback reasoning
4. **Progressive Enhancement**: AST features enhance text-based functionality seamlessly

#### Production Stability Features

1. **Zero Critical Failures**: No complete feature outages due to parser issues
2. **Error Recovery**: Graceful handling of malformed or incomplete code
3. **Memory Efficiency**: Fallback modes use 40-60% less memory
4. **Scalable Architecture**: Fallbacks can be enhanced independently of primary features

These comprehensive fallback mechanisms ensure the LSP remains highly functional and reliable during all phases of development, from initial code writing through complex refactoring scenarios.

## Troubleshooting Text-Based Fallbacks (*Diataxis: How-to* - Debugging and resolving fallback issues)

This section provides comprehensive guidance for diagnosing and resolving issues with text-based fallback mechanisms in the LSP server.

### Common Fallback Scenarios (*Diataxis: Reference* - When fallbacks activate)

#### **Automatic Fallback Triggers**

1. **AST Parse Failures**
   - **Cause**: Syntax errors, incomplete code, unsupported Perl constructs
   - **Detection**: Check LSP server logs for "Primary extraction failed" messages
   - **Resolution**: Fallbacks activate automatically; fix syntax errors to restore AST-based features

2. **AST Unavailability**  
   - **Cause**: Parser timeout, memory constraints, very large files
   - **Detection**: Document state shows `ast: None` in debug logs
   - **Resolution**: Reduce file size, increase parser timeout, or use fallback-only mode

3. **Feature-Specific Failures**
   - **Cause**: AST node structure changes, missing node types, traversal errors
   - **Detection**: Feature works for some files but fails for others
   - **Resolution**: Check AST structure compatibility, update node traversal patterns

#### **Forced Fallback Modes (Testing/Development)**

1. **Environment Variable Activation**
   ```bash
   # Force fallbacks for comprehensive testing
   export LSP_TEST_FALLBACKS=1
   perl-lsp --stdio
   
   # Force fallbacks in production (debugging)
   export LSP_FORCE_FALLBACKS=1
   perl-lsp --stdio
   ```

2. **Configuration-Based Activation**
   ```rust
   // In LSP server initialization
   let fallback_mode = config.get("fallback_mode").unwrap_or(false);
   server.set_fallback_mode(fallback_mode);
   ```

### Diagnostic Techniques (*Diataxis: How-to* - Identifying fallback issues)

#### **1. Fallback Activation Logging**

```bash
# Enable detailed logging to see when fallbacks activate
perl-lsp --stdio --log-level debug 2>lsp-debug.log

# Monitor fallback activation in real-time
tail -f lsp-debug.log | grep -E "(fallback|Primary.*failed)"
```

**Expected Output**:
```
[DEBUG] Primary workspace symbols extraction failed in handle_workspace_symbols: AST unavailable. Using fallback.
[DEBUG] Text-based symbol extraction returned 12 symbols for test.pl
[DEBUG] Fallback extraction completed in 4.2ms
```

#### **2. Performance Impact Assessment**

```rust
#[test]
fn diagnose_fallback_performance() {
    let large_file_content = include_str!("test_files/large_perl_file.pl");
    
    // Measure AST-based performance
    let start = Instant::now();
    let ast_result = server.extract_symbols_ast(&ast, "test.pl", "");
    let ast_duration = start.elapsed();
    
    // Measure fallback performance
    let start = Instant::now();
    let fallback_result = server.extract_symbols_fallback(large_file_content);
    let fallback_duration = start.elapsed();
    
    println!("AST: {}ms ({} symbols)", ast_duration.as_millis(), ast_result.len());
    println!("Fallback: {}ms ({} symbols)", fallback_duration.as_millis(), fallback_result.len());
    println!("Overhead: {}%", ((fallback_duration.as_millis() * 100) / ast_duration.as_millis()) - 100);
}
```

#### **3. Accuracy Validation**

```rust
#[test]
fn validate_fallback_accuracy() {
    let test_files = vec![
        "basic_subroutines.pl",
        "package_declarations.pl", 
        "complex_nested.pl"
    ];
    
    for file in test_files {
        let content = std::fs::read_to_string(file).unwrap();
        let ast = parse_perl(&content);
        
        // Extract symbols using both methods
        let ast_symbols = server.extract_symbols_ast(&ast, file, "");
        let fallback_symbols = server.extract_symbols_fallback(&content);
        
        // Compare results
        let accuracy = calculate_symbol_accuracy(&ast_symbols, &fallback_symbols);
        println!("{}: {}% accuracy", file, accuracy);
        
        // Flag significant differences
        if accuracy < 85.0 {
            println!("‚ö†Ô∏è  Low accuracy detected in {}", file);
            print_symbol_differences(&ast_symbols, &fallback_symbols);
        }
    }
}
```

### Resolving Common Issues (*Diataxis: How-to* - Fix specific fallback problems)

#### **Issue 1: Missing Symbols in Fallback Mode**

**Symptoms**:
- Workspace symbols show fewer results than expected
- Outline view missing subroutines or packages
- Go-to-definition fails for known symbols

**Diagnosis**:
```bash
# Check regex pattern matching
echo "sub test_function { return 42; }" | grep -E "sub\s+([A-Za-z_][A-Za-z0-9_]*)"

# Verify fallback symbol extraction
LSP_TEST_FALLBACKS=1 perl-lsp --stdio < test_request.json
```

**Resolution**:
```rust
// Enhanced regex patterns for better symbol detection
lazy_static! {
    static ref ENHANCED_SUB_REGEX: Regex = Regex::new(
        r"^\s*sub\s+([A-Za-z_][A-Za-z0-9_]*)\s*(?:\([^)]*\))?\s*[{;]"
    ).unwrap();
    
    static ref ENHANCED_PACKAGE_REGEX: Regex = Regex::new(
        r"^\s*package\s+([A-Za-z_:][A-Za-z0-9_:]*)\s*(?:v?[\d.]+)?\s*;"
    ).unwrap();
}
```

#### **Issue 2: Excessive Fallback Performance Overhead**

**Symptoms**:
- LSP responses consistently >1000ms slower in fallback mode
- Memory usage spikes during fallback operations  
- Editor becomes unresponsive during symbol extraction

**Diagnosis**:
```rust
// Profile regex compilation overhead
use std::time::Instant;

fn benchmark_regex_performance() {
    let content = include_str!("large_test_file.pl");
    
    // Test compiled regex performance
    let start = Instant::now();
    for _ in 0..100 {
        ENHANCED_SUB_REGEX.captures_iter(content).count();
    }
    let compiled_duration = start.elapsed();
    
    // Test on-demand regex compilation
    let start = Instant::now();
    for _ in 0..100 {
        let regex = Regex::new(r"sub\s+([A-Za-z_][A-Za-z0-9_]*)").unwrap();
        regex.captures_iter(content).count();
    }
    let dynamic_duration = start.elapsed();
    
    println!("Compiled: {}ms, Dynamic: {}ms", 
             compiled_duration.as_millis(), 
             dynamic_duration.as_millis());
}
```

**Resolution**:
```rust
// Use lazy_static for regex compilation optimization
lazy_static! {
    static ref FALLBACK_REGEXES: FallbackPatterns = FallbackPatterns::new();
}

struct FallbackPatterns {
    sub_regex: Regex,
    package_regex: Regex,
    variable_regex: Regex,
}

impl FallbackPatterns {
    fn new() -> Self {
        Self {
            sub_regex: Regex::new(r"^\s*sub\s+([A-Za-z_][A-Za-z0-9_]*)").unwrap(),
            package_regex: Regex::new(r"^\s*package\s+([A-Za-z_:][A-Za-z0-9_:]*)").unwrap(),
            variable_regex: Regex::new(r"^\s*(my|our|local)\s+([%$@][A-Za-z_][A-Za-z0-9_]*)").unwrap(),
        }
    }
}
```

#### **Issue 3: Inaccurate Reference Counting in Code Lens**

**Symptoms**:
- Code lens shows incorrect reference counts
- Method calls not distinguished from function calls
- Cross-file references not detected

**Diagnosis**:
```rust
#[test]
fn diagnose_reference_counting() {
    let content = r#"
        sub test_function { return 42; }
        
        my $obj = SomeClass->new();
        $obj->test_function();     # Method call
        test_function();           # Function call
        main::test_function();     # Qualified call
    "#;
    
    // Test different reference counting approaches
    let total_refs = count_all_references(content, "test_function");
    let method_refs = count_method_references(content, "test_function");
    let function_refs = count_function_references(content, "test_function");
    
    println!("Total: {}, Method: {}, Function: {}", total_refs, method_refs, function_refs);
    assert_eq!(total_refs, method_refs + function_refs);
}
```

**Resolution**:
```rust
// Enhanced reference counting with pattern differentiation
fn count_references_enhanced(&self, text: &str, symbol_name: &str) -> (usize, usize) {
    let method_pattern = format!(r"->\s*{}\s*\(", regex::escape(symbol_name));
    let function_pattern = format!(r"\b{}\s*\(", regex::escape(symbol_name));
    
    let method_regex = Regex::new(&method_pattern).unwrap();
    let function_regex = Regex::new(&function_pattern).unwrap();
    
    let method_count = method_regex.find_iter(text).count();
    
    // Function calls excluding those already counted as method calls
    let mut function_count = 0;
    for mat in function_regex.find_iter(text) {
        let start = mat.start();
        // Check if this is not preceded by -> (method call)
        if start < 2 || &text[start-2..start] != "->" {
            function_count += 1;
        }
    }
    
    (method_count, function_count)
}
```

### Advanced Troubleshooting (*Diataxis: How-to* - Complex debugging scenarios)

#### **Scenario 1: Fallbacks Working But Results Inconsistent**

**Investigation Steps**:
1. **Compare AST vs Fallback Results**:
   ```bash
   # Generate comparison report
   LSP_TEST_FALLBACKS=1 cargo test test_fallback_accuracy -- --nocapture > fallback_report.txt
   ```

2. **Analyze Pattern Matching Edge Cases**:
   ```rust
   #[test]
   fn analyze_pattern_edge_cases() {
       let edge_cases = vec![
           "sub test { } # Comment with 'sub' keyword",
           "my $var = 'sub test_function';",  // String containing 'sub'
           "=pod\nsub test_in_pod { }\n=cut", // POD documentation
           "# sub commented_out_function { }",  // Commented code
       ];
       
       for case in edge_cases {
           let symbols = extract_symbols_fallback(case);
           println!("Case: {} -> {} symbols", case, symbols.len());
       }
   }
   ```

#### **Scenario 2: Performance Regression in Fallback Mode**

**Investigation Steps**:
1. **Profile Regex Performance**:
   ```bash
   # Use cargo flamegraph for detailed profiling
   cargo install flamegraph
   cargo flamegraph --test fallback_performance_test
   ```

2. **Memory Usage Analysis**:
   ```rust
   use std::alloc::{GlobalAlloc, Layout, System};
   
   #[global_allocator]
   static ALLOCATOR: TrackingAllocator<System> = TrackingAllocator(System);
   
   #[test]
   fn analyze_fallback_memory() {
       let before = ALLOCATOR.allocated();
       let _symbols = extract_symbols_fallback(large_content);
       let after = ALLOCATOR.allocated();
       println!("Memory used: {} bytes", after - before);
   }
   ```

### Configuration and Optimization (*Diataxis: Reference* - Fallback tuning parameters)

#### **Environment Variables**

```bash
# Core fallback control
export LSP_TEST_FALLBACKS=1           # Force fallbacks for testing
export LSP_FORCE_FALLBACKS=1          # Force fallbacks in production
export LSP_FALLBACK_TIMEOUT=5000      # Fallback timeout in milliseconds

# Performance tuning
export LSP_FALLBACK_MAX_FILE_SIZE=1000000  # Skip fallbacks for files >1MB
export LSP_FALLBACK_REGEX_CACHE_SIZE=100   # Compiled regex cache size
export LSP_FALLBACK_SYMBOL_LIMIT=1000      # Max symbols per file in fallback mode

# Debugging
export LSP_FALLBACK_DEBUG=1           # Enable detailed fallback logging
export LSP_FALLBACK_STATS=1           # Enable performance statistics
```

#### **Runtime Configuration**

```rust
pub struct FallbackConfig {
    pub enabled: bool,
    pub timeout_ms: u64,
    pub max_file_size: usize,
    pub symbol_limit: usize,
    pub enable_stats: bool,
}

impl Default for FallbackConfig {
    fn default() -> Self {
        Self {
            enabled: true,
            timeout_ms: 5000,
            max_file_size: 1_000_000, // 1MB
            symbol_limit: 1000,
            enable_stats: false,
        }
    }
}
```

### Success Metrics and Validation (*Diataxis: Reference* - Measuring fallback effectiveness)

#### **Key Performance Indicators (KPIs)**

1. **Feature Availability**: Target 99.9% (measured as successful responses / total requests)
2. **Performance Overhead**: Target <300% of AST-based performance
3. **Accuracy**: Target >85% symbol detection accuracy vs AST-based results
4. **Memory Efficiency**: Target <2x memory usage vs AST-based mode
5. **Error Rate**: Target <0.1% fallback failures

#### **Monitoring and Alerting**

```rust
// Built-in metrics collection
pub struct FallbackMetrics {
    pub activations: u64,
    pub total_requests: u64, 
    pub avg_duration_ms: f64,
    pub accuracy_rate: f64,
    pub memory_usage_mb: f64,
}

impl FallbackMetrics {
    pub fn availability_percentage(&self) -> f64 {
        if self.total_requests == 0 { return 0.0; }
        ((self.total_requests - self.failed_requests) as f64 / self.total_requests as f64) * 100.0
    }
}
```

This comprehensive troubleshooting guide ensures that text-based fallback mechanisms can be effectively debugged, optimized, and monitored in production environments.

## Enhanced LSP Workflow Integration ‚≠ê **NEW: Issue #145** (*Diataxis: Explanation* - Complete workflow architecture)

The Perl LSP server now implements a comprehensive **Parse ‚Üí Index ‚Üí Navigate ‚Üí Complete ‚Üí Analyze ‚Üí Execute** workflow pipeline that provides complete language server functionality.

### Workflow Pipeline Architecture (*Diataxis: Explanation* - System design)

**Complete LSP Workflow Pipeline**:
```
Parse ‚Üí Index ‚Üí Navigate ‚Üí Complete ‚Üí Analyze ‚Üí Execute
  ‚Üì       ‚Üì        ‚Üì         ‚Üì          ‚Üì         ‚Üì
 AST   Symbols   Refs    Suggest    Check    Actions
~1ms   ~10ms   ~40ms     ~50ms     ~100ms     ~2s
```

#### Phase 1: Parse (*Diataxis: Reference* - AST generation)
```rust
// Enhanced parsing with incremental support
pub struct EnhancedParser {
    pub incremental: Option<IncrementalParser>,
    pub error_recovery: ParseErrorRecovery,
    pub performance_monitor: ParsePerformanceMonitor,
}

impl EnhancedParser {
    // <1ms parsing with 70-99% node reuse efficiency
    pub fn parse_with_incremental(&mut self, content: &str) -> Result<Node, ParseError> {
        if let Some(incremental) = &mut self.incremental {
            incremental.parse_incremental(content) // Reuse existing nodes
        } else {
            self.parse_full(content) // Full parse for new documents
        }
    }
}
```

#### Phase 2: Index (*Diataxis: Reference* - Symbol indexing)
```rust
// Dual indexing strategy for comprehensive coverage
pub struct WorkspaceIndexer {
    qualified_index: HashMap<String, Vec<SymbolInfo>>,
    bare_index: HashMap<String, Vec<SymbolInfo>>,
    cross_file_refs: HashMap<String, Vec<Location>>,
}

impl WorkspaceIndexer {
    // ~10ms indexing with dual pattern storage
    pub fn index_symbols(&mut self, ast: &Node, package: &str) {
        for symbol in ast.symbols() {
            // Index under both qualified and bare forms (98% reference coverage)
            let qualified_name = format!("{}::{}", package, symbol.name);

            self.qualified_index.entry(qualified_name.clone()).or_default().push(symbol.clone());
            self.bare_index.entry(symbol.name.clone()).or_default().push(symbol);
        }
    }
}
```

#### Phase 3: Navigate (*Diataxis: Reference* - Definition/reference resolution)
```rust
// Enhanced cross-file navigation with dual pattern matching
pub struct NavigationProvider {
    workspace_index: Arc<WorkspaceIndexer>,
    module_resolver: Option<ModuleResolver>,
}

impl NavigationProvider {
    // ~40ms cross-file navigation with fallback strategies
    pub fn find_definition(&self, symbol: &str) -> Vec<Location> {
        let mut locations = Vec::new();

        // Try qualified name first
        if let Some(refs) = self.workspace_index.qualified_index.get(symbol) {
            locations.extend(refs.iter().map(|r| r.location.clone()));
        }

        // Try bare name for broader coverage
        if let Some(idx) = symbol.rfind("::") {
            let bare_name = &symbol[idx + 2..];
            if let Some(refs) = self.workspace_index.bare_index.get(bare_name) {
                locations.extend(refs.iter().map(|r| r.location.clone()));
            }
        }

        locations
    }
}
```

#### Phase 4: Complete (*Diataxis: Reference* - Code completion)
```rust
// Enhanced completion with context awareness and module resolution
pub struct CompletionProvider {
    ast: Node,
    source: String,
    workspace_index: Arc<WorkspaceIndexer>,
    module_resolver: Option<ModuleResolver>,
}

impl CompletionProvider {
    // ~50ms completion with comprehensive suggestions
    pub fn get_completions(&self, position: Position) -> Vec<CompletionItem> {
        let mut completions = Vec::new();

        // Local scope completions
        completions.extend(self.get_local_completions(position));

        // Workspace symbol completions with dual indexing
        completions.extend(self.get_workspace_completions(position));

        // Module completions with resolver integration
        if let Some(resolver) = &self.module_resolver {
            completions.extend(self.get_module_completions(position, resolver));
        }

        completions
    }
}
```

#### Phase 5: Analyze (*Diataxis: Reference* - Diagnostic analysis)
```rust
// Enhanced analysis with performance monitoring
pub struct DiagnosticAnalyzer {
    syntax_analyzer: SyntaxAnalyzer,
    semantic_analyzer: SemanticAnalyzer,
    performance_monitor: AnalysisPerformanceMonitor,
}

impl DiagnosticAnalyzer {
    // ~100ms analysis with comprehensive error detection
    pub fn analyze_document(&self, ast: &Node, content: &str) -> Vec<Diagnostic> {
        let mut diagnostics = Vec::new();

        // Syntax-level analysis
        diagnostics.extend(self.syntax_analyzer.check_syntax(ast));

        // Semantic-level analysis
        diagnostics.extend(self.semantic_analyzer.check_semantics(ast, content));

        // Performance validation
        self.performance_monitor.record_analysis_time(diagnostics.len());

        diagnostics
    }
}
```

#### Phase 6: Execute ‚≠ê **NEW: Issue #145** (*Diataxis: Reference* - Command execution)
```rust
// Enhanced executeCommand with dual analyzer strategy
pub struct ExecuteCommandProvider {
    parser: Arc<EnhancedParser>,
    workspace_index: Arc<WorkspaceIndexer>,
    performance_monitor: ExecutionPerformanceMonitor,
}

impl ExecuteCommandProvider {
    // ~2s execution with comprehensive tool integration
    pub fn execute_command(&self, command: &str, arguments: Vec<Value>) -> Result<Value, String> {
        match command {
            "perl.runCritic" => {
                let file_path = self.extract_file_path(&arguments)?;

                // Dual analyzer strategy: external perlcritic + built-in fallback
                if self.command_exists("perlcritic") {
                    match self.run_external_critic(file_path) {
                        Ok(result) => return Ok(result),
                        Err(_) => {
                            // Seamless fallback to built-in analyzer
                        }
                    }
                }

                // Built-in analyzer provides 100% availability
                self.run_builtin_critic(file_path)
            },
            "perl.runTests" => self.execute_test_runner(&arguments),
            "perl.runFile" => self.execute_perl_file(&arguments),
            _ => Err(format!("Unknown command: {}", command))
        }
    }
}
```

### Integration Patterns (*Diataxis: How-to Guide* - Development best practices)

#### **Workflow State Management**
```rust
// Central workflow coordinator
pub struct LSPWorkflowCoordinator {
    parser: EnhancedParser,
    indexer: WorkspaceIndexer,
    navigator: NavigationProvider,
    completer: CompletionProvider,
    analyzer: DiagnosticAnalyzer,
    executor: ExecuteCommandProvider,
}

impl LSPWorkflowCoordinator {
    // Complete document processing pipeline
    pub fn process_document(&mut self, uri: &str, content: &str) -> LSPWorkflowResult {
        // Phase 1: Parse
        let ast = self.parser.parse_with_incremental(content)?;

        // Phase 2: Index
        self.indexer.index_symbols(&ast, &self.extract_package(&ast));

        // Phase 3-6: On-demand processing for LSP requests
        LSPWorkflowResult {
            ast,
            ready_for_navigation: true,
            ready_for_completion: true,
            ready_for_analysis: true,
            ready_for_execution: true,
        }
    }
}
```

#### **Performance Integration with Adaptive Threading**
```rust
// Enhanced threading configuration for complete workflow
pub struct WorkflowPerformanceConfig {
    pub parsing_threads: usize,
    pub indexing_threads: usize,
    pub analysis_threads: usize,
    pub execution_timeout: Duration,
}

impl WorkflowPerformanceConfig {
    // Adaptive configuration based on system capabilities
    pub fn adaptive_config() -> Self {
        let thread_count = std::thread::available_parallelism().unwrap().get();

        Self {
            parsing_threads: 1, // Single-threaded for consistency
            indexing_threads: (thread_count / 2).max(1),
            analysis_threads: (thread_count / 4).max(1),
            execution_timeout: if thread_count <= 2 {
                Duration::from_secs(15) // High contention
            } else if thread_count <= 4 {
                Duration::from_secs(10) // Medium contention
            } else {
                Duration::from_secs(5)  // Low contention
            },
        }
    }
}
```

### Quality Assurance Integration (*Diataxis: How-to Guide* - Testing complete workflows)

#### **End-to-End Workflow Testing**
```bash
# Test complete workflow pipeline
cargo test -p perl-lsp --test lsp_comprehensive_e2e_test

# Test individual workflow phases
cargo test -p perl-parser --test parsing_performance_tests     # Phase 1: Parse
cargo test -p perl-parser --test workspace_indexing_tests     # Phase 2: Index
cargo test -p perl-lsp --test navigation_integration_tests    # Phase 3: Navigate
cargo test -p perl-lsp --test completion_integration_tests    # Phase 4: Complete
cargo test -p perl-lsp --test diagnostic_integration_tests    # Phase 5: Analyze
cargo test -p perl-lsp --test execute_command_integration_tests # Phase 6: Execute

# Performance validation across complete workflow
RUST_TEST_THREADS=2 cargo test -p perl-lsp -- --test-threads=2
```

#### **Workflow Performance Benchmarks**
```bash
# Validate workflow performance targets
cargo test -p perl-lsp --test workflow_performance_tests

# Individual phase performance validation
cargo bench parsing_phase        # Target: <1ms
cargo bench indexing_phase       # Target: <10ms
cargo bench navigation_phase     # Target: <40ms
cargo bench completion_phase     # Target: <50ms
cargo bench analysis_phase       # Target: <100ms
cargo bench execution_phase      # Target: <2s
```

The enhanced LSP workflow integration provides a complete, performance-optimized language server architecture while maintaining the performance improvements achieved in PR #140.
