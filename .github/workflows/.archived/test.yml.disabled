name: Tests

on:
  workflow_dispatch: {}
  pull_request:
    branches: [ main, master ]
    types: [labeled]

# Cancel in-flight runs on new pushes (saves minutes)
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  CARGO_TERM_COLOR: always

jobs:
  test:
    timeout-minutes: 45
    if: |
      github.event_name == 'workflow_dispatch' ||
      contains(github.event.pull_request.labels.*.name, 'ci:tests')
    runs-on: ${{ matrix.os }}
    defaults:
      run:
        shell: bash
    strategy:
      matrix:
        os: [ubuntu-22.04, windows-2022]
        rust: [stable]
      fail-fast: false  # Continue testing other platforms if one fails
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Install Rust
      uses: dtolnay/rust-toolchain@stable
      with:
        toolchain: ${{ matrix.rust }}
    
    - name: Install perltidy and perlcritic (Ubuntu)
      if: matrix.os == 'ubuntu-22.04'
      run: |
        sudo apt-get update
        sudo apt-get install -y perltidy libperl-critic-perl
    
    - name: Cache cargo dependencies
      uses: Swatinem/rust-cache@v2
      with:
        key: ${{ runner.os }}-${{ matrix.rust }}-${{ hashFiles('Cargo.lock') }}
        cache-on-failure: true

    - name: Install nextest
      uses: taiki-e/install-action@nextest

    - name: Check for tautological tests
      shell: bash
      run: |
        echo "Checking for tautological assertions..."
        
        # Pattern 1: is_some() || is_none()
        if grep -r "is_some().*||.*is_none()" crates/perl-parser/tests/ 2>/dev/null; then
          echo "ERROR: Found is_some() || is_none() patterns"
          exit 1
        fi
        
        # Pattern 2: !X.is_empty() || X.is_empty() (same receiver tautology)
        if grep -rE '!\s*([A-Za-z0-9_\.]+)\.is_empty\(\)\s*\|\|\s*\1\.is_empty\(\)' crates/perl-parser/tests/ 2>/dev/null; then
          echo "ERROR: Found tautological !X.is_empty() || X.is_empty() patterns"
          exit 1
        fi
        
        # Pattern 3: assert!(true) or assert!(false)
        if grep -E 'assert!\((true|false)\)' crates/perl-parser/tests/ 2>/dev/null; then
          echo "ERROR: Found hardcoded assert!(true/false)"
          exit 1
        fi
        
        echo "✓ No tautological assertions found"
    
    - name: Build
      run: cargo build --locked --verbose
    
    - name: Build LSP server
      run: cargo build --locked -p perl-lsp --bin perl-lsp --verbose
    
    - name: Run tests (nextest, lean, CI guards)
      env:
        CARGO_BUILD_JOBS: 2
        RUSTFLAGS: "-Cdebuginfo=0 -Copt-level=1 --cfg ci"
      run: |
        # Skip crash/fuzz buckets in default PR runs; those live in label-gated sweeps.
        cargo nextest run --locked --workspace --no-fail-fast \
          -- --skip crash_reproducer_test --skip fuzz_regression_test

    - name: Run E2E tests
      run: cargo test --locked -p perl-parser --tests --verbose
    
    - name: Check if jq is available (Linux)
      run: |
        if ! command -v jq &> /dev/null; then
          echo "jq not found, installing..."
          if [[ "${{ matrix.os }}" == "ubuntu-22.04" ]]; then
            sudo apt-get update && sudo apt-get install -y jq
          fi
        fi

    - name: Install jq (Windows)
      if: matrix.os == 'windows-2022'
      shell: pwsh
      run: choco install jq -y

    - name: Verify test discovery (CI regression guard)
      shell: bash
      run: |
        echo "Verifying comprehensive test discovery..."
        
        # Build test executables and count tests
        echo "Building test executables..."
        EXECS=$(cargo test --locked -p perl-parser --no-run --message-format=json 2>/dev/null | \
          jq -r 'select(.reason=="compiler-artifact") | select(.profile.test==true) | .executable // empty' | \
          grep -v '^$' || true)
        
        if [ -z "$EXECS" ]; then
          echo "❌ No test executables found!"
          exit 1
        fi
        
        TOTAL_TESTS=0
        ZERO_TEST_FILES=""
        
        # Process executables safely (handles paths with spaces)
        while IFS= read -r exe; do
          test_name=$(basename "$exe")
          test_name=${test_name%.exe}  # strip .exe on Windows
          test_name=$(printf "%s" "$test_name" | sed 's/-[[:xdigit:]]\{8,\}$//')
          
          # Count tests using --list
          if ! LIST_OUTPUT=$("$exe" --list --format=terse 2>&1); then
            echo "⚠️  Failed to list tests in $test_name"
            continue
          fi
          
          # CRLF-safe counting (handles Windows line endings)
          TEST_COUNT=$(
            awk -F': ' '{ x=$NF; sub(/\r$/,"",x); if (x=="test") c++ } END{ print c+0 }' <<< "$LIST_OUTPUT"
          )
          
          if [ "$TEST_COUNT" -eq 0 ]; then
            echo "⚠️  WARNING: 0 tests found in $test_name"
            ZERO_TEST_FILES="$ZERO_TEST_FILES $test_name"
          else
            echo "✓ Found $TEST_COUNT tests in $test_name"
            TOTAL_TESTS=$((TOTAL_TESTS + TEST_COUNT))
          fi
        done <<EOF
        $EXECS
        EOF
        
        echo ""
        echo "Total tests discovered: $TOTAL_TESTS"
        
        # Baseline drift guard with configurable threshold
        BASELINE=${BASELINE_TOTAL_TESTS:-720}   # set in env, or fall back to 720
        THRESHOLD_PCT=${BASELINE_DROP_PCT:-5}   # allow 5% drop
        
        # integer math: allowed = baseline * (100 - threshold) / 100
        ALLOWED=$(( BASELINE * (100 - THRESHOLD_PCT) / 100 ))
        MIN_EXPECTED_TESTS=500  # Absolute minimum as fallback
        
        # Use the stricter of the two thresholds
        if [ "$ALLOWED" -gt "$MIN_EXPECTED_TESTS" ]; then
          MIN_EXPECTED_TESTS=$ALLOWED
        fi
        
        if [ "$TOTAL_TESTS" -lt "$MIN_EXPECTED_TESTS" ]; then
          echo "❌ ERROR: Test count dropped: $TOTAL_TESTS < $MIN_EXPECTED_TESTS"
          echo "  Baseline: $BASELINE tests"
          echo "  Max allowed drop: ${THRESHOLD_PCT}%"
          echo "  Minimum allowed: $ALLOWED tests"
          echo "This may indicate a test discovery regression!"
          exit 1
        fi
        
        if [ -n "$ZERO_TEST_FILES" ]; then
          echo ""
          echo "⚠️  WARNING: Test files with 0 tests:"
          for zero_file in $ZERO_TEST_FILES; do
            echo "  - $zero_file"
          done
        fi
        
        echo "✅ Test discovery check passed: $TOTAL_TESTS tests found"
    
    - name: Run incremental tests (feature-gated)
      run: cargo test --locked -p perl-parser --features incremental --verbose
    
    - name: Build with deny warnings (soft check)
      if: matrix.os == 'ubuntu-22.04'
      run: |
        echo "Building with warnings as errors (soft check)..."
        RUSTFLAGS="-D warnings" cargo build --locked --release -p perl-lsp --bin perl-lsp || echo "Warning: Build with -D warnings failed"
      continue-on-error: true

  clippy:
    timeout-minutes: 20
    if: |
      github.event_name == 'workflow_dispatch' ||
      contains(github.event.pull_request.labels.*.name, 'ci:tests')
    runs-on: ubuntu-22.04
    defaults:
      run:
        shell: bash
    steps:
    - uses: actions/checkout@v4

    - name: Install Rust
      uses: dtolnay/rust-toolchain@stable
      with:
        toolchain: stable
        components: clippy

    - name: Run clippy (first-party)
      run: |
        echo "Running clippy on first-party crates..."
        cargo clippy --locked \
          -p perl-lexer -p perl-parser -p perl-lsp -p perl-corpus -p perl-dap \
          --all-targets -- -D warnings 2>&1 | tee clippy-output.txt
        
        # Count warnings
        WARNING_COUNT=$(grep -c "warning:" clippy-output.txt || echo "0")
        echo "Found $WARNING_COUNT clippy warnings"
        
        # Fail if there are errors (not warnings)
        if grep -q "error:" clippy-output.txt; then
          echo "ERROR: Clippy found errors"
          exit 1
        fi
      continue-on-error: true  # Don't fail on warnings yet

  format:
    timeout-minutes: 10
    if: |
      github.event_name == 'workflow_dispatch' ||
      contains(github.event.pull_request.labels.*.name, 'ci:tests')
    runs-on: ubuntu-22.04
    steps:
    - uses: actions/checkout@v4
    
    - name: Install Rust
      uses: dtolnay/rust-toolchain@stable
      with:
        toolchain: stable
        components: rustfmt
    
    - name: Check formatting
      if: runner.os != 'Windows'
      run: cargo fmt --all --check
